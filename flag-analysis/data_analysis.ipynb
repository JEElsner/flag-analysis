{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = pd.read_feather('../data/all_flags.feather')\n",
    "tf_idf = pd.read_feather('../data/flag_description_tf_idf.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'flag-country': flags.apply(lambda r: f'{r['Flag(s)']}-{r['State']}', axis=1)}).join(tf_idf)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf_idf\n",
    "Y = data['flag-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca = PCA().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "cum_var = np.sqrt(np.cumsum(pca.singular_values_**2) / np.sum(pca.singular_values_**2))\n",
    "ax.plot(cum_var)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var = np.searchsorted(cum_var, 0.99)\n",
    "all_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn import metrics\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "categorizers = list()\n",
    "\n",
    "for pca_modes in [2, 3, 5, 10, 20, 50, 100, all_var]:\n",
    "    for k in range(3, 31):\n",
    "        pipe = make_pipeline(\n",
    "            PCA(n_components=pca_modes, random_state=932),\n",
    "            KMeans(n_clusters=k, random_state=42),\n",
    "            memory=cachedir\n",
    "        )\n",
    "        \n",
    "        categorizers.append(pipe)\n",
    "\n",
    "model_metrics = dict()\n",
    "for cat in categorizers:\n",
    "    cat.fit(X, Y)\n",
    "    labels = cat.predict(X)\n",
    "    categories = {label: Y[labels == label].values for label in np.unique(labels)}\n",
    "    avg = np.average(list(map(len, categories.values())))\n",
    "    # var = np.average((np.fromiter(map(len, categories.values()), dtype=int) - avg)**2)\n",
    "    silhouette_score = metrics.silhouette_score(X, cat.get_params()['kmeans'].labels_, metric='euclidean')\n",
    "    model_metrics[cat] = silhouette_score\n",
    "\n",
    "best = pipe = max(categorizers, key=model_metrics.get)\n",
    "print(best.get_params()['pca__n_components'], best.get_params()['kmeans__n_clusters'], model_metrics[best])\n",
    "\n",
    "categories = {label: Y[labels == label].values for label in np.unique(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model, metric in model_metrics.items():\n",
    "#     print(f'k={model.get_params()['kmeans__n_clusters']}\\t: {metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handpicked model\n",
    "\n",
    "best = pipe = make_pipeline(\n",
    "    PCA(n_components=2),\n",
    "    KMeans(n_clusters=10)\n",
    ")\n",
    "\n",
    "best.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_2d = pipe.named_steps['kmeans'].cluster_centers_[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "pts = (X @ pca.components_[:2].T).T.values\n",
    "# plt.scatter(*pts)\n",
    "\n",
    "for i, (x, y) in enumerate(pts.T):\n",
    "    image = plt.imread(flags['path'][i])\n",
    "    offset_img = OffsetImage(image, zoom=0.1)\n",
    "    abb = AnnotationBbox(offset_img, (x, y), xycoords='data', frameon=False, zorder=0)\n",
    "    ax.add_artist(abb)\n",
    "\n",
    "ax.update_datalim(pts.T)\n",
    "ax.autoscale()\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# plt.scatter(*centers_2d.T, zorder=20, color='r', alpha=0.5)\n",
    "voronoi_plot_2d(Voronoi(centers_2d), ax=ax)\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "ax.set_title('Flags on the first two PCs')\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "\n",
    "ax.set_facecolor('lightgray')\n",
    "fig.savefig('../writeup/res/flag-pca.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to analyze the principal components for patterns\n",
    "\n",
    "components = pca.inverse_transform(pca.components_[:3] @ X.T)\n",
    "components.columns = tf_idf.columns\n",
    "\n",
    "for idx, component in components.iterrows():\n",
    "    sorted_words = sorted(components.columns, key=lambda c: component[c])\n",
    "    \n",
    "    print(f'{idx}: {sorted_words[:3]} vs {sorted_words[-3:]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"elliptical\" only shows up in the description for Costa Rica, and two of these words are conjunctions, this may not actually be that useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to see what the \"average\" flag per category is described as\n",
    "# I'm not sure how to 'undo' tf-idf, but luckily sklearn has a TfidfVectorizer, which I will hopefully implement soon...\n",
    "\n",
    "avg_flags = pd.DataFrame(pipe.named_steps['pca'].inverse_transform(pipe.named_steps['kmeans'].cluster_centers_), columns=pipe.feature_names_in_)\n",
    "avg_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This runs really slow for some reason\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for label, group in categories.items():\n",
    "    for i, flag in enumerate(group):\n",
    "        image = plt.imread(flags[data['flag-country'] == flag]['path'].values[0])\n",
    "        offset_img = OffsetImage(image, zoom=0.1)\n",
    "        abb = AnnotationBbox(offset_img, (label, i))\n",
    "        ax.add_artist(abb)\n",
    "\n",
    "ax.autoscale()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gmm_models = list()\n",
    "gmm_metrics = dict()\n",
    "\n",
    "gmm_cache = mkdtemp()\n",
    "\n",
    "for pc_modes in [2, 3, 5, 10, 20, 50, 100, all_var]:\n",
    "    for components in range(2, 30):\n",
    "        gmm = make_pipeline(\n",
    "            PCA(n_components=pc_modes),\n",
    "            GaussianMixture(n_components=5),\n",
    "            memory=gmm_cache\n",
    "        )\n",
    "        gmm_models.append(gmm)\n",
    "\n",
    "        gmm.fit(X)\n",
    "        gmm_metrics[gmm] = metrics.silhouette_score(X, gmm.predict(X), metric='euclidean')\n",
    "\n",
    "best_gmm = max(gmm_models, key=gmm_metrics.get)\n",
    "print(f'Best GMM: {best_gmm.get_params()['pca__n_components']}, {best_gmm.get_params()['gaussianmixture__n_components']}: {gmm_metrics[best_gmm]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gmm = make_pipeline(\n",
    "    PCA(n_components=2),\n",
    "    GaussianMixture(n_components=5),\n",
    "    memory=gmm_cache\n",
    ")\n",
    "\n",
    "best_gmm.fit(X)\n",
    "\n",
    "metrics.silhouette_score(X, best_gmm.predict(X), metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./best_gmm.pkl', mode='wb') as f:\n",
    "    pickle.dump(best_gmm, f)\n",
    "\n",
    "# with open('./best_gmm.pkl', mode='rb') as f:\n",
    "#     best_gmm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "pcs = [0, 1]\n",
    "pts = (X @ pca.components_[pcs].T).T.values\n",
    "# plt.scatter(*pts)\n",
    "\n",
    "for i, (x, y) in enumerate(pts.T):\n",
    "    image = plt.imread(flags['path'][i])\n",
    "    offset_img = OffsetImage(image, zoom=0.1)\n",
    "    abb = AnnotationBbox(offset_img, (x, y), xycoords='data', frameon=False, zorder=0)\n",
    "    ax.add_artist(abb)\n",
    "\n",
    "ax.update_datalim(pts.T)\n",
    "ax.autoscale()\n",
    "\n",
    "means = best_gmm.get_params()['gaussianmixture'].means_\n",
    "covariances = best_gmm.get_params()['gaussianmixture'].covariances_\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html#sphx-glr-auto-examples-mixture-plot-gmm-py\n",
    "for i, (mean, covar, color) in enumerate(zip(means, covariances, colors)):\n",
    "    v, w = linalg.eigh(covar)\n",
    "    v = 2.0 * np.sqrt(2.0) * np.sqrt(v)\n",
    "    u = w[pcs[0]] / linalg.norm(w[pcs[0]])\n",
    "\n",
    "    # Plot an ellipse to show the Gaussian component\n",
    "    angle = np.atan2(u[pcs[1]], u[pcs[0]])\n",
    "    angle = 180.0 * angle / np.pi  # convert to degrees\n",
    "    ell = mpl.patches.Ellipse(mean, v[pcs[0]], v[pcs[1]], angle=180.0 + angle, color=color, label=f\"GMM Category {i}\")\n",
    "    ell.set_clip_box(ax.bbox)\n",
    "    ell.set_alpha(0.3)\n",
    "    ax.add_artist(ell)\n",
    "\n",
    "ax.set_title('Flags on the first two PCs')\n",
    "ax.set_xlabel(f'PC {pcs[0]+1}')\n",
    "ax.set_ylabel(f'PC {pcs[1]+1}')\n",
    "ax.set_facecolor('lightgray')\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig('../writeup/res/flag-gmm.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_categories = dict()\n",
    "\n",
    "for flag, cat in zip(flags['Flag(s)'], best_gmm.predict(X)):\n",
    "    l = gmm_categories.get(int(cat), list())\n",
    "    l.append(flag)\n",
    "    gmm_categories[int(cat)] = l\n",
    "\n",
    "{cat: len(values) for cat, values in gmm_categories.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(gmm_categories, headers=gmm_categories.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined k-means GMM plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "pcs = [0, 1]\n",
    "pts = (X @ pca.components_[pcs].T).T.values\n",
    "# plt.scatter(*pts)\n",
    "\n",
    "# Plot the points\n",
    "for i, (x, y) in enumerate(pts.T):\n",
    "    image = plt.imread(flags['path'][i])\n",
    "    offset_img = OffsetImage(image, zoom=0.1)\n",
    "    abb = AnnotationBbox(offset_img, (x, y), xycoords='data', frameon=False, zorder=0)\n",
    "    ax.add_artist(abb)\n",
    "\n",
    "ax.update_datalim(pts.T)\n",
    "ax.autoscale()\n",
    "\n",
    "# Plot the GMM confidence intervals\n",
    "means = best_gmm.get_params()['gaussianmixture'].means_\n",
    "covariances = best_gmm.get_params()['gaussianmixture'].covariances_\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/mixture/plot_gmm.html#sphx-glr-auto-examples-mixture-plot-gmm-py\n",
    "for i, (mean, covar, color) in enumerate(zip(means, covariances, colors)):\n",
    "    v, w = linalg.eigh(covar)\n",
    "    v = 2.0 * np.sqrt(2.0) * np.sqrt(v)\n",
    "    u = w[pcs[0]] / linalg.norm(w[pcs[0]])\n",
    "\n",
    "    # Plot an ellipse to show the Gaussian component\n",
    "    angle = np.atan2(u[pcs[1]], u[pcs[0]])\n",
    "    angle = 180.0 * angle / np.pi  # convert to degrees\n",
    "    ell = mpl.patches.Ellipse(mean, v[pcs[0]], v[pcs[1]], angle=180.0 + angle, color=color, label=f\"GMM Category {i}\")\n",
    "    ell.set_clip_box(ax.bbox)\n",
    "    ell.set_alpha(0.3)\n",
    "    ax.add_artist(ell)\n",
    "\n",
    "# Plot the k-means clusters as a Voronoi diagram\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# plt.scatter(*centers_2d.T, zorder=20, color='r', alpha=0.5)\n",
    "voronoi_plot_2d(Voronoi(centers_2d), ax=ax)\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "# Titles etc\n",
    "ax.set_title('Flags on the first two PCs')\n",
    "ax.set_xlabel(f'PC {pcs[0]+1}')\n",
    "ax.set_ylabel(f'PC {pcs[1]+1}')\n",
    "ax.set_facecolor('lightgray')\n",
    "ax.legend()\n",
    "\n",
    "fig.savefig('../writeup/res/flags-kmeans-gmm.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  scipy.spatial.distance import cdist\n",
    "\n",
    "pca138 = PCA(138).fit(X)\n",
    "reduced = pca138.transform(X)\n",
    "\n",
    "distances = cdist(reduced, reduced, metric='euclidean')\n",
    "\n",
    "no_self_dist = distances.copy()\n",
    "no_self_dist[np.diag_indices(distances.shape[0])] = np.inf\n",
    "\n",
    "dist_table = pd.DataFrame(data={'flag-country': Y,\n",
    "                                'avg_dist': np.mean(distances, axis=1),\n",
    "                                'min_dist': np.min(no_self_dist, axis=1)},)\n",
    "dist_table.sort_values(by='min_dist', inplace=True, ascending=False)\n",
    "dist_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_table[dist_table['flag-country'] == 'Canada-Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flag-analysis-3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
